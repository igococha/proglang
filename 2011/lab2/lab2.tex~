\documentclass{article}

\usepackage{a4wide}
\usepackage[breaklinks=true,
        colorlinks=true,urlcolor=blue,pdfpagemode=None]{hyperref}

\newcommand{\fname}[1]{\texttt{#1}}

\begin{document}
\thispagestyle{empty}

\newcommand{\negra}[1]{\textbf{#1}}

\section*{Language Processors Lab 2 - Week 2}

\textbf{READ: } JavaCC Documentation.\\

\textbf{GOAL:} to implement a simple JavaCC-generated lexical analyser and use it as input to the RPN Calculator introduced in the previos lab.

The main functionality of the RPN Calculator was implemented by the StackMachine and RPN classes. The tokenisation (lexical analysis) of the input was performed by the Lexer class, which was called from the RPN class as shown by the following code extract:

\begin{verbatim}
Lexer lexer = new Lexer(e);      // Tokenises String e
Token token;
machine.clearStack();            // Clears contents of stack 
while (lexer.hasNextToken()) {   // Loop while there's a toke left
  token = lexer.getNextToken();  // gets next token from Lexer
  switch (token.kind) {          // inspects type of token
   case INTEGER: 
      machine.pushInteger(Integer.parseInt(token.image));
      break;
   case PLUS: machine.plus(); break;
   case MINUS: machine.subtract(); break;
   case MULT: machine.multiply(); break;
   case DIV: machine.divide(); break;
 }
}
...
System.out.println("Result: "+machine.popInteger()); // prints top of the stack
\end{verbatim}

We want to replace the functionality of the Lexer class by a Lexical Analyzer generated by JavaCC.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{A Trivial Lexical Analyzer}

Fire up a Unix shell window.  Your current directory should be  your home directory. Check the contents of  your current directory with the ls command:
\begin{verbatim}
   ls
\end{verbatim}
If you have already created your \verb+LanguageProcessors+ directory, make it your current directory by executing \verb+cd LanguageProcessors+. Otherwise do the following
\begin{verbatim}
   mkdir LanguageProcessors
   cd LanguageProcesoors
\end{verbatim}
Once inside the \verb+LanguageProcessors+ directory, Create the lab2 directory and make it your current directory:
\begin{verbatim}
   mkdir lab2
   cd lab2
   pwd
\end{verbatim}
The result of the last command should be \verb+<local_host>/<username>/LanguageProcessors/lab2+.

In this lab we will be using three commands: javacc, javac (the java compiler) and java (the java virtual machine). You should already have \verb+java+ as part of your environment though \verb+javac+ may not be of it. Check if you have both commands installed by typing:
\begin{verbatim}
   javac -version
   java -version
\end{verbatim}
If any of the commands above fail. type the following:
\begin{verbatim}
   module add java
\end{verbatim}
Do the same with javacc by typing:
\begin{verbatim}
  module add javacc
\end{verbatim}

We will start with a simple JavaCC lexical analyzer which recognises a small number of token types. Make sure you are currently at the lab2 directory and copy the \verb+LexTest.jj+, \verb+StackMachine.java+ and \verb+StackMachineException.java+ file from the module's Moodle lab2 space.
You can see the contents of the JavaCC  file with:
\begin{verbatim}
   more LexTest.jj
\end{verbatim}
In order to run javacc with LexTest.jj as input, type the following:
\begin{verbatim}
   javacc LexTest.jj
\end{verbatim}
This produces a Java program in various files. This program is the lexical analyser and recognizes the tokens specified in  \verb+LexTest.jj+. Now compile these Java classes with:
\begin{verbatim}
   javac LexTest.java
\end{verbatim}
And then run the program:
\begin{verbatim}
   java LexTest
\end{verbatim}
Type in some identifer names and integers and see what happens. For example, what is the output of the following inputs?
\begin{verbatim}
Enter input> + 8 9 xy z
Enter input > 134 / -
\end{verbatim}


\section*{The JavaCC file - Explanation}

Fire up your editor of choice (KEdit, Xemacs) and load \verb+LexTest.jj+. 
Inspect \verb+LexTest.jj+ for full details. A JavaCC file has three parts:
\begin{itemize}
\item The first part, delimited by \verb+PARSER_BEGIN(<parser_name>)+ and \verb+PARSER_END(<parser_name>)+, must include the Parser's class definition. The class should be named after the parser i.e. \verb+<parser_name>+. In our case, \verb+<parser_name>+ is \verb+LextTest+. JavaCC will generate a set of .java files, including \verb+LexTest.java+ with a default \verb+main+ method. We can re-define the \verb+main+ method - as shown in this example - as well as add more methods and fields. In our example, we have re-defined the main method in order to display the greeting message and call the parser.
\item The second part is dedicated to lexical specifications using regular expressions. It defines the tokens recognised by the lexical analyser. In our example, the two forms of token (SKIP and TOKEN) are demonstrated, along with most of the kinds of JavaCC regular expressions, as well as the use of local definitions (prefixed by a \verb+#+ in a TOKEN definition).\\
We have the following tokens: \verb+END_INPUT, INTEGER_LITERAL, PLUS, MINUS, IDENTIFIER+.
\item The third part contains the syntax specifications (grammar) of our language. Our example uses a very simple grammar:
\begin{verbatim}
 (<INTEGER_LITERAL> |  <PLUS> |  <MINUS> | <IDENTIFIER> )* <END_INPUT>
\end{verbatim}
which says: accept a sequence (any length, including zero) of these tokens, followed by the \verb+<END_INPUT>+ token. Notice that \verb+TokenList()+ is divided into two parts: the first part is used for variable declarations (\verb+Token+) while the second for the syntax specification itself.

It is possible to capture the token recognised in a Token object (\verb+t = <PLUS>+) and then to access and print its kind (from the table tokenImage indexed by Token field \verb+kind+) and the corresponding string that was matched (from Token field \verb+image+) by the analyser. These are fields that belong to the pre-defined JavaCC class \verb+Token+.

It is also possible to add Java code by placing it between curly braces. For example, we have added code to print information about every matched tokeN;
\begin{verbatim}
{ System.out.println ("token found: "+ tokenImage[t.kind]+
                       " (`"+t.image+"')"); }
\end{verbatim} 
\end{itemize}

The syntax definitions part of this JavaCC specification simply matches all defined tokens and prints them out. 

\section*{Modifying the Analyser}

We would like to add three more tokens in order to capture the multiplication operator, the division operator and real numbers of the form 0.45, 34.567, etc. We will use the following token specifications:
\begin{verbatim}
TOKEN           REGULAR EXPRESSION
-----           -------------------
MULT            *
DIV             /
FLOAT_LITERAL   <DIGIT>+ . <DIGIT>+ 
\end{verbatim}
Three steps are required:
\begin{itemize}
\item \textbf{EXTEND} the specification of the PLUS and MINUS tokens with:
\begin{verbatim}
TOKEN : /* Operators */
{ 
  < PLUS: "+" > 
 | < MINUS: "-" >
 | < MULT: "*" >
 | < DIV: "/" >
}
\end{verbatim}
\item \textbf{ADD} the following token specification:
\begin{verbatim}
TOKEN : /* Literal Floating Point */
{
  < FLOAT_LITERAL: (<DIGIT>)+ "." (<DIGIT>)+ >
}
\end{verbatim}
\item \textbf{UPDATE} the grammar with:
\begin{verbatim}
 (t = <INTEGER_LITERAL> | t = <PLUS> | t = <MINUS> | t = <MULT> |
 t = <DIV> | t = <IDENTIFIER> | t = <FLOAT_LITERAL>)
\end{verbatim}
in order to inform the parser to accept the new tokens.
\item Run \verb+javacc LexTest.jj+ and recompile the new files with \verb+javac LexTest.java+.\\
Run the new program with \verb+java LexTest+ and test a few examples that use the new tokens e.g. \verb+89 7 zz / 34.56 -+.
\end{itemize}


\section*{Implementing the Calculator}

Now we are ready to integrate our parser/lexer with the StackMachine in order to implement the RPN calculator.

Replace the spacification of \verb+TokenList+ with:
\begin{verbatim}
void TokenList() :
{Token t;
StackMachine machine = new StackMachine();}
{
   (
     (t = <INTEGER_LITERAL> | t = <PLUS> | t = <MINUS> | t = <MULT> |
      t = <DIV> | t = <IDENTIFIER> | t = <FLOAT_LITERAL>)
{ 
  try {
  switch (t.kind) {          // inspects type of token
     case INTEGER_LITERAL: 
        machine.pushInteger(Integer.parseInt(t.image));
        break;
     case PLUS: machine.plus(); break;
     case MINUS: machine.subtract(); break;
     case MULT: machine.multiply(); break;
     case DIV: machine.divide(); break;
     default: System.out.println("Unknown Token "+tokenImage[t.kind]); return;
   }
  } catch (StackMachineException sme) {
    	System.out.println(sme);
        return;
  }
}
)* <END_INPUT>
{
  try {
    System.out.println("Result: "+machine.popInteger());
  } catch (StackMachineException sme) {
    System.out.println("Error while reading result\n"+sme);
  }
}
}
\end{verbatim}

Run javacc once more, re-compile and execute the program. Test a few examples e.g. \textbf{34 56 78 + -}. Does it work? What happens when you include an identifier? What happens when you use a floating point?

\textbf{Exercise:} Extend the calculator so it accepts our floating point tokens. Note that the stack machine only accepts integers.


\end{document}

